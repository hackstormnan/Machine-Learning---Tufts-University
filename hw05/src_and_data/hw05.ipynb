{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name and ID\n",
    "\n",
    "Jianan Xu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW05 Code\n",
    "\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 05 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file, along with your COLLABORATORS.txt file and the two tree images (PDFs generated using `graphviz` within the code), to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/tufts/spring2021/comp135).\n",
    "\n",
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You should start by computing the two heuristic values for the toy data described in the assignment handout. You should then load the two versions of the abalone data, compute the two heuristic values on features (for the simplified data), and then build decision trees for each set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Compute both heuristics for toy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the left part of A, the majority is O, and for the right part of A, the majority is X. After counting, the left side are two O total, \n",
    "# which is all correct. The right side are two O and 4 X, so there are two mistakes (two O). Overall, the answer for A should be 6/8\n",
    "\n",
    "# Using the same way of computing, For B, the majority of left side is O, and there is one mistake (one X). For the right side, the majority\n",
    "# is X, and there is one mistake (one X). So the answer for B is 6/8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For the A: \n",
    "# the H(A) = -(4/8 * log2(4/8) + 4/8 * log2(4/8)) = 1\n",
    "# the Remainder(A) = (2/8 * H(A1) + 6/8 * H(A2))\n",
    "# H(A1) = -(0/2 * log2(0/2) + 2/2 * log2(2/2)) = 0\n",
    "# H(A2) = -(2/6 * log2(2/6) + 4/6 * log2(4/6)) = 0.918\n",
    "# Remainder(A) = 0.6885\n",
    "\n",
    "# Gain(A) = H(A) = Remainder(A) = 1-0.6885 = 0.3115\n",
    "\n",
    "#For the B:\n",
    "# Using the same way of computing, the H(A) = H(B) = 1\n",
    "# the Remainder(B) = (4/8 * H(B1) + 4/8 * H(B2))\n",
    "# H(B1) = -(3/4 * log2(3/4) + 1/4 * log2(1/4)) = 0.81\n",
    "# H(B2) = -(3/4 * log2(3/4) + 1/4 * log2(1/4)) = 0.81\n",
    "# Remainder(B) = 0.81\n",
    "\n",
    "# Gain(B) = H(B) = Remainder(B) = 1-0.81 = 0.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discussion of results.\n",
    "\n",
    "so if we use the part A's answer to get the results, their accuracy is same, so we cannot distinguish which one is better.\n",
    "if we use the part B's answer, the gain for A is higher, which means that the A is better for this situation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Compute both heuristics for simplified abalone data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: \n",
      "diam_mm: \n",
      "length_mm:  \n",
      "is_male: \n",
      "[[2316, 3176], [2266, 3176], [2230, 3176], [1864, 3176]]\n"
     ]
    }
   ],
   "source": [
    "x_test = np.loadtxt('./data_abalone/small_binary_x_test.csv', delimiter=',', skiprows=1)\n",
    "x_train = np.loadtxt('./data_abalone/small_binary_x_train.csv', delimiter=',', skiprows=1)\n",
    "y_test = np.loadtxt('./data_abalone/3class_y_test.csv', delimiter=',', skiprows=1)\n",
    "y_train = np.loadtxt('./data_abalone/3class_y_train.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "\n",
    "top_row = pd.read_csv('./data_abalone/small_binary_x_train.csv', nrows=0)\n",
    "full_feature_names = np.array(top_row.columns)\n",
    "classes = [0, 1, 2]\n",
    "\n",
    "def get_elements(index):   \n",
    "    m0_0 = 0\n",
    "    m0_1 = 0\n",
    "    m0_2 = 0\n",
    "    m1_0 = 0\n",
    "    m1_1 = 0\n",
    "    m1_2 = 0\n",
    "    l = []\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        is_male = x_train[i][index]\n",
    "        label = y_train[i]\n",
    "\n",
    "        if is_male == 0 and label == 0:        \n",
    "            m0_0 = m0_0 + 1\n",
    "        if is_male == 0 and label == 1:\n",
    "            m0_1 = m0_1 + 1\n",
    "        if is_male == 0 and label == 2:\n",
    "            m0_2 = m0_2 + 1\n",
    "\n",
    "        if is_male == 1 and label == 0:\n",
    "            m1_0 = m1_0 + 1\n",
    "        if is_male == 1 and label == 1:\n",
    "            m1_1 = m1_1 + 1\n",
    "        if is_male == 1 and label == 2:\n",
    "            m1_2 = m1_2 + 1\n",
    "\n",
    "    l.append(m0_0)\n",
    "    l.append(m0_1)\n",
    "    l.append(m0_2)\n",
    "    l.append(m1_0)\n",
    "    l.append(m1_1)\n",
    "    l.append(m1_2)\n",
    "    return l\n",
    "\n",
    "\n",
    "def get_ans(l):\n",
    "    \n",
    "    big_0 = 0\n",
    "    length = int(len(l) / 2)\n",
    "    total_0 = 0\n",
    "    for i in range(0, length):\n",
    "        if big_0 < l[i]:\n",
    "            big_0 = l[i]\n",
    "        total_0 = total_0 + l[i]\n",
    "        \n",
    "    big_1 = 0\n",
    "    total_1 = 0\n",
    "    for i in range(length, len(l)):\n",
    "        if (big_1 < l[i]):\n",
    "            big_1 = l[i]\n",
    "        total_1 = total_1 + l[i]\n",
    "        \n",
    "    ans = []\n",
    "    ans.append(big_0 + big_1)\n",
    "    ans.append(total_0 + total_1)\n",
    "    return ans\n",
    "        \n",
    "        \n",
    "lst = []\n",
    "ans_list1 = []\n",
    "\n",
    "for i in range(len(x_train[0])): \n",
    "    l = get_elements(i)\n",
    "    ans = get_ans(l)\n",
    "    lst.append(l)\n",
    "    ans_list1.append(ans)\n",
    "    \n",
    "ans_list1.sort(reverse=True)\n",
    "\n",
    "print(\"height_mm: \")\n",
    "print(\"diam_mm: \")\n",
    "print(\"length_mm:  \")\n",
    "print(\"is_male: \")\n",
    "print(ans_list1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "height_mm: \n",
      "diam_mm: \n",
      "length_mm:  \n",
      "is_male: \n",
      "[0.17302867291002477, 0.1500706886802703, 0.13543816377043694, 0.024516482271752293]\n"
     ]
    }
   ],
   "source": [
    "# For the A: \n",
    "# the H(A) = -(4/8 * log2(4/8) + 4/8 * log2(4/8)) = 1\n",
    "# the Remainder(A) = (2/8 * H(A1) + 6/8 * H(A2))\n",
    "# H(A1) = -(0/2 * log2(0/2) + 2/2 * log2(2/2)) = 0\n",
    "# H(A2) = -(2/6 * log2(2/6) + 4/6 * log2(4/6)) = 0.918\n",
    "# Remainder(A) = 0.6885\n",
    "\n",
    "# Gain(A) = H(A) = Remainder(A) = 1-0.6885 = 0.3115\n",
    "\n",
    "#For the B:\n",
    "# Using the same way of computing, the H(A) = H(B) = 1\n",
    "# the Remainder(B) = (4/8 * H(B1) + 4/8 * H(B2))\n",
    "# H(B1) = -(3/4 * log2(3/4) + 1/4 * log2(1/4)) = 0.81\n",
    "# H(B2) = -(3/4 * log2(3/4) + 1/4 * log2(1/4)) = 0.81\n",
    "# Remainder(B) = 0.81\n",
    "\n",
    "# Gain(B) = H(B) = Remainder(B) = 1-0.81 = 0.19\n",
    "\n",
    "\n",
    "def get_gain(l):\n",
    "    total_0 = 0\n",
    "    length = int(len(l)/2)\n",
    "    for i in range(0, length):                           #all branches 0 (x_train)\n",
    "        total_0 = total_0 + l[i]\n",
    "\n",
    "    total_1 = 0\n",
    "    for i in range(length, len(l)):\n",
    "        total_1 = total_1 + l[i]                         #all branches 1 (x_train)\n",
    "        \n",
    "\n",
    "    m_0 = l[0] + l[3]                                     #all O\n",
    "    m_1 = l[1] + l[4]                                     #all rectangle\n",
    "    m_2 = l[2] + l[5]                                     #all X\n",
    "    total_m = m_0 + m_1 + m_2\n",
    "\n",
    "    m0_0 = l[0]\n",
    "    m0_1 = l[1]\n",
    "    m0_2 = l[2]\n",
    "    \n",
    "    m1_0 = l[3]\n",
    "    m1_1 = l[4]\n",
    "    m1_2 = l[5]\n",
    "    \n",
    "    H = -(m_0/total_m * np.log2(m_0/total_m) + (m_1/total_m) * np.log2(m_1/total_m) + (m_2/total_m) * np.log2(m_2/total_m))\n",
    "\n",
    "    \n",
    "    H_1 = -(m0_0/total_0 * np.log2(m0_0/total_0) + m0_1/total_0 * np.log2(m0_1/total_0) + m0_2/total_0 * np.log2(m0_2/total_0))\n",
    "    H_2 = -(m1_0/total_1 * np.log2(m1_0/total_1) + m1_1/total_1 * np.log2(m1_1/total_1) + m1_2/total_1 * np.log2(m1_2/total_1))\n",
    "    \n",
    "    R = (total_0/total_m) * H_1 + (total_1/total_m) * H_2\n",
    "    G = H-R\n",
    "    return G\n",
    "\n",
    "ans_list = []\n",
    "for i in range(len(lst)):\n",
    "    ans = get_gain(lst[i])\n",
    "    ans_list.append(ans)\n",
    "    \n",
    "print(\"height_mm: \")\n",
    "print(\"diam_mm: \")\n",
    "print(\"length_mm:  \")\n",
    "print(\"is_male: \")\n",
    "ans_list.sort(reverse=True)\n",
    "print(ans_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 1, 3]\n",
      "4\n",
      "4\n",
      "1.0\n",
      "0.8112781244591328\n",
      "0.8112781244591328\n",
      "0.18872187554086717\n"
     ]
    }
   ],
   "source": [
    "# # test on question 1\n",
    "# x_train = [[0],[0],[0], [0], [1], [1], [1], [1]]\n",
    "# y_train = [0, 0, 0, 1, 0, 1, 1, 1]\n",
    "# m = get_elements(0)\n",
    "# new_lst = []\n",
    "# for i in range(len(m)):\n",
    "#     if i == 2 or i == 5:\n",
    "#         continue\n",
    "#     new_lst.append(m[i])\n",
    "    \n",
    "# print(new_lst)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# total_0 = 0\n",
    "# length = int(len(new_lst)/2)\n",
    "\n",
    "# for i in range(0, length):\n",
    "#     total_0 = total_0 + new_lst[i]\n",
    "\n",
    "# total_1 = 0\n",
    "# for i in range(length, len(new_lst)):\n",
    "#     total_1 = total_1 + new_lst[i]\n",
    "\n",
    "# m_0 = new_lst[0] + new_lst[2]                                     #all 0\n",
    "# m_1 = new_lst[1] + new_lst[3]                                     #all 1\n",
    "# total_m = m_0 + m_1\n",
    "\n",
    "# print(total_0)\n",
    "# print(total_1)\n",
    "# H = -(m_0/total_m * np.log2(m_0/total_m) + (m_1/total_m) * np.log2(m_1/total_m))\n",
    "# print(H)\n",
    "\n",
    "\n",
    "# m0_0 = new_lst[0]\n",
    "# m0_1 = new_lst[1]\n",
    "# m1_0 = new_lst[2]\n",
    "# m1_1 = new_lst[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# H_1 = -(m0_0/total_0 * np.log2(m0_0/total_0) + m0_1/total_0 * np.log2(m0_1/total_0))\n",
    "# H_2 = -(m1_0/total_1 * np.log2(m1_0/total_1) + m1_1/total_1 * np.log2(m1_1/total_1))\n",
    "# print(H_1)\n",
    "# print(H_2)\n",
    "\n",
    "# R = (total_0/total_m) * H_1 + (total_1/total_m) * H_2\n",
    "# G = H-R\n",
    "\n",
    "# print(G)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Generate decision trees for full- and restricted-feature data\n",
    "\n",
    "#### (a) Print accuracy values and generate tree images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_x_test = np.loadtxt('./data_abalone/x_test.csv', delimiter=',', skiprows=1)\n",
    "com_x_train = np.loadtxt('./data_abalone/x_train.csv', delimiter=',', skiprows=1)\n",
    "com_y_test = np.loadtxt('./data_abalone/y_test.csv', delimiter=',', skiprows=1)\n",
    "com_y_train = np.loadtxt('./data_abalone/y_train.csv', delimiter=',', skiprows=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score is: \n",
      "0.7326826196473551\n",
      "test_score is: \n",
      "0.722\n"
     ]
    }
   ],
   "source": [
    "import sklearn.tree\n",
    "\n",
    "classifier = sklearn.tree.DecisionTreeClassifier(criterion= 'entropy')\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "train_score = classifier.score(x_train, y_train)\n",
    "test_score = classifier.score(x_test, y_test)\n",
    "\n",
    "print(\"train_score is: \")\n",
    "print(train_score)\n",
    "print(\"test_score is: \")\n",
    "print(test_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'simplified_final_pdf.pdf'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "fit_value = classifier.fit(x_train, y_train)\n",
    "graph = sklearn.tree.export_graphviz(fit_value, out_file=None)\n",
    "\n",
    "final_pdf = graphviz.Source(graph)\n",
    "final_pdf.render(\"simplified_final_pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score is: \n",
      "1.0\n",
      "test_score is: \n",
      "0.196\n"
     ]
    }
   ],
   "source": [
    "com_classifier = sklearn.tree.DecisionTreeClassifier(criterion= 'entropy')\n",
    "com_classifier.fit(com_x_train, com_y_train)\n",
    "\n",
    "com_train_score = com_classifier.score(com_x_train, com_y_train)\n",
    "com_test_score = com_classifier.score(com_x_test, com_y_test)\n",
    "\n",
    "print(\"train_score is: \")\n",
    "print(com_train_score)\n",
    "print(\"test_score is: \")\n",
    "print(com_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complicated_final_pdf.pdf'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_fit_value = classifier.fit(com_x_train, com_y_train)\n",
    "com_graph = sklearn.tree.export_graphviz(com_fit_value, out_file=None)\n",
    "\n",
    "com_final_pdf = graphviz.Source(com_graph)\n",
    "com_final_pdf.render(\"complicated_final_pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Discuss the results seen for the two trees\n",
    "\n",
    "*TODO*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can see the score is different. for the complicated version of data, it is a 1 for train_score and 0.2 for test_score, which means that\n",
    "# this is a overfitting. The score for the simplified version of data seems normal. \n",
    "\n",
    "# the two trees are different that one is pretty simple and has 2 branches with 3 features. Meanwhile, the complicated tree has tons of\n",
    "# branches and features, which can produce a very large decision tree. \n",
    "\n",
    "# The mistake that the simple version of data make is that it has two branches (two leaves) every time the tree spread out. There is a\n",
    "# mistake that for example, the most left bottom value, it suppose to be 0 on label 1 and 2. However, there still value on the label 1,\n",
    "# which is different to the ideal situation. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
