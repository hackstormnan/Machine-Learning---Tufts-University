{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Overall idea\n",
    "## Processing of the data.\n",
    "* 1. Binarize the data (turn each image into a black and white image) and place each pixel with a pixel value less than or equal to 0.4 at 0 and greater than 0.4 at 1\n",
    "* 2. Expand the training set by flipping each image vertically and adding it to the training set\n",
    "\n",
    "## Parameter selection.\n",
    "Select the best regularization parameter C for the logistic regression classifier with Bayesian optimizer to achieve the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 1. 0. 1.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 1. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (12000, 784)\n",
      "[0 1 1 ... 1 0 0] (12000,)\n"
     ]
    }
   ],
   "source": [
    "# Read the data and convert it to a numpy array, where traget is converted to a one-dimensional array\n",
    "data = pd.read_csv(\"./data_trouser_dress/troudress_train_x.csv\").values\n",
    "target = pd.read_csv(\"./data_trouser_dress/troudress_train_y.csv\").values.reshape(-1)\n",
    "print(data,data.shape)\n",
    "print(target,target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 784)\n"
     ]
    }
   ],
   "source": [
    "# Dividing the data set into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data,target,test_size=0.3,random_state=0)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, without processing the data, fit the logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9306  \u001b[0m | \u001b[0m 0.417   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9419  \u001b[0m | \u001b[95m 0.000114\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9344  \u001b[0m | \u001b[0m 0.3023  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9414  \u001b[0m | \u001b[0m 0.1468  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9442  \u001b[0m | \u001b[95m 0.09234 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.1863  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9331  \u001b[0m | \u001b[0m 0.3456  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 0.3968  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.5388  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.9475  \u001b[0m | \u001b[95m 0.05673 \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.9492  \u001b[0m | \u001b[95m 0.04103 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8578  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9414  \u001b[0m | \u001b[0m 8.364e-0\u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9492  \u001b[0m | \u001b[0m 0.04037 \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.9508  \u001b[0m | \u001b[95m 0.001318\u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.9544  \u001b[0m | \u001b[95m 0.002808\u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.9547  \u001b[0m | \u001b[95m 0.004164\u001b[0m |\n",
      "| \u001b[95m 20      \u001b[0m | \u001b[95m 0.9553  \u001b[0m | \u001b[95m 0.005916\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9544  \u001b[0m | \u001b[0m 0.007782\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9547  \u001b[0m | \u001b[0m 0.009984\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9525  \u001b[0m | \u001b[0m 0.01216 \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9511  \u001b[0m | \u001b[0m 0.01484 \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9517  \u001b[0m | \u001b[0m 0.01767 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.9514  \u001b[0m | \u001b[0m 0.02055 \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9503  \u001b[0m | \u001b[0m 0.02352 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9506  \u001b[0m | \u001b[0m 0.02663 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9503  \u001b[0m | \u001b[0m 0.02968 \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.9503  \u001b[0m | \u001b[0m 0.03285 \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9497  \u001b[0m | \u001b[0m 0.03612 \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 0.04499 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 0.04842 \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.9483  \u001b[0m | \u001b[0m 0.05205 \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9472  \u001b[0m | \u001b[0m 0.0605  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.9475  \u001b[0m | \u001b[0m 0.06452 \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9472  \u001b[0m | \u001b[0m 0.06833 \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.9461  \u001b[0m | \u001b[0m 0.07221 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9456  \u001b[0m | \u001b[0m 0.07694 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.945   \u001b[0m | \u001b[0m 0.08196 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.9367  \u001b[0m | \u001b[0m 0.2598  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.9048  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.9447  \u001b[0m | \u001b[0m 0.08679 \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9442  \u001b[0m | \u001b[0m 0.101   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 0.1092  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.9258  \u001b[0m | \u001b[0m 0.679   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 0.1162  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8116  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 0.1257  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.9627  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9386  \u001b[0m | \u001b[0m 0.2212  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.9442  \u001b[0m | \u001b[0m 0.09669 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9267  \u001b[0m | \u001b[0m 0.6038  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.4916  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.7651  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.4542  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 0.1051  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9264  \u001b[0m | \u001b[0m 0.6417  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 0.1337  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.5712  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.9406  \u001b[0m | \u001b[0m 0.1552  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.9336  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9425  \u001b[0m | \u001b[0m 0.1204  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 0.1401  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 0.3709  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.9281  \u001b[0m | \u001b[0m 0.5151  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8815  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.9406  \u001b[0m | \u001b[0m 0.1641  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.94    \u001b[0m | \u001b[0m 0.1728  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.7884  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8346  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.9356  \u001b[0m | \u001b[0m 0.2808  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.9333  \u001b[0m | \u001b[0m 0.324   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.7427  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.1954  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.2044  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.9372  \u001b[0m | \u001b[0m 0.2398  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.6997  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.1794  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.9436  \u001b[0m | \u001b[0m 0.1126  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.9264  \u001b[0m | \u001b[0m 0.6229  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.9392  \u001b[0m | \u001b[0m 0.2117  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.4357  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.4729  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9261  \u001b[0m | \u001b[0m 0.6604  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.9814  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.9267  \u001b[0m | \u001b[0m 0.5875  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.9275  \u001b[0m | \u001b[0m 0.555   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9414  \u001b[0m | \u001b[0m 0.1296  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.9482  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.9383  \u001b[0m | \u001b[0m 0.2292  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.9192  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.9314  \u001b[0m | \u001b[0m 0.3838  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.9478  \u001b[0m | \u001b[0m 0.05431 \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9325  \u001b[0m | \u001b[0m 0.3581  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.2496  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.9358  \u001b[0m | \u001b[0m 0.2698  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.9411  \u001b[0m | \u001b[0m 0.1509  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.935   \u001b[0m | \u001b[0m 0.2913  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.9339  \u001b[0m | \u001b[0m 0.313   \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.9286  \u001b[0m | \u001b[0m 0.5032  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.9406  \u001b[0m | \u001b[0m 0.1598  \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.527   \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.9333  \u001b[0m | \u001b[0m 0.3347  \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8696  \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8931  \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.7766  \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8462  \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.9394  \u001b[0m | \u001b[0m 0.1909  \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.9403  \u001b[0m | \u001b[0m 0.1684  \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.8231  \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 0.7314  \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.7539  \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.9308  \u001b[0m | \u001b[0m 0.4068  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.1999  \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.9258  \u001b[0m | \u001b[0m 0.6893  \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.7099  \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.9392  \u001b[0m | \u001b[0m 0.2164  \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.9297  \u001b[0m | \u001b[0m 0.4262  \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.4823  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.9381  \u001b[0m | \u001b[0m 0.2343  \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.4635  \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.4449  \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.6133  \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.9447  \u001b[0m | \u001b[0m 0.08953 \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.9264  \u001b[0m | \u001b[0m 0.6323  \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.9261  \u001b[0m | \u001b[0m 0.651   \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.9261  \u001b[0m | \u001b[0m 0.6697  \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.9907  \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.9239  \u001b[0m | \u001b[0m 0.9722  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.2547  \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.5469  \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.9453  \u001b[0m | \u001b[0m 0.07937 \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.5632  \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.5793  \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.9267  \u001b[0m | \u001b[0m 0.5956  \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.9356  \u001b[0m | \u001b[0m 0.2753  \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.9369  \u001b[0m | \u001b[0m 0.2447  \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.9414  \u001b[0m | \u001b[0m 0.1434  \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# The optimal hyperparameter C, the regularization parameter, is selected using a Bayesian optimizer\n",
    "def f_score(C):\n",
    "    lr = LogisticRegression(max_iter=200,C=C)\n",
    "    lr.fit(X_train,y_train)\n",
    "    acc = accuracy_score(y_test,lr.predict(X_test))\n",
    "    return acc     # The goal of adjusting parameters to maximize accuracy\n",
    "\n",
    "# Determine the range of parameter values\n",
    "pbounds = {'C': (0,1)}\n",
    "\n",
    "# Constructing a Bayesian Optimizer\n",
    "opt = BayesianOptimization(\n",
    "    f=f_score,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 2 prints all, verbose = 1 prints the maximum value found in the run, verbose = 0 prints nothing\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Start running\n",
    "opt.maximize(\n",
    "    init_points=10,  # Steps of random search\n",
    "    n_iter=130  # Number of iterations to perform Bayesian optimization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C: 0.0059162059945443435\n"
     ]
    }
   ],
   "source": [
    "C1 = opt.max['params'][\"C\"]     # Take the best parameters\n",
    "print(\"best C:\",C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=200,C=0.0059162059945443435)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "x_test = np.loadtxt('data_trouser_dress/troudress_test_x.csv', delimiter=',', skiprows=1)\n",
    "yproba1_test = model.predict_proba(x_test)[:, 1]\n",
    "np.savetxt('yproba1_test.txt', yproba1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9552777777777778\n"
     ]
    }
   ],
   "source": [
    "# Training on the training set\n",
    "lr1 = LogisticRegression(max_iter=200,C=C1)\n",
    "lr1.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Test accuracy in test set\n",
    "pre = lr1.predict(X_test)\n",
    "acc = accuracy_score(pre,y_test)\n",
    "print(\"Accuracy on the test set:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the training data is binarized (turning each image into a black and white image), with the pixel value of each pixel less than or equal to 0.4 placed at 0 and greater than 0.4 placed at 1. Then, again, a Bayesian optimizer is used to select the best regularization parameter C for the logistic regression classifier to achieve the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "# Binarization of all training images\n",
    "for i in range(len(X_train_copy)):\n",
    "    for j in range(len(X_train_copy[i])):\n",
    "        if X_train_copy[i][j] <= 0.4:\n",
    "            X_train_copy[i][j] = 0\n",
    "        else:\n",
    "            X_train_copy[i][j] = 1\n",
    "X_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_copy = X_test.copy()\n",
    "# Binarization of all test images\n",
    "for i in range(len(X_test_copy)):\n",
    "    for j in range(len(X_test_copy[i])):\n",
    "        if X_test_copy[i][j] <= 0.4:\n",
    "            X_test_copy[i][j] = 0\n",
    "        else:\n",
    "            X_test_copy[i][j] = 1\n",
    "X_test_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.417   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9219  \u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.9356  \u001b[0m | \u001b[95m 0.000114\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.9283  \u001b[0m | \u001b[0m 0.3023  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9319  \u001b[0m | \u001b[0m 0.1468  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9361  \u001b[0m | \u001b[95m 0.09234 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9308  \u001b[0m | \u001b[0m 0.1863  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.3456  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.3968  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 0.5388  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9194  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.9442  \u001b[0m | \u001b[95m 0.04805 \u001b[0m |\n",
      "| \u001b[95m 13      \u001b[0m | \u001b[95m 0.9444  \u001b[0m | \u001b[95m 0.03535 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.8556  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9347  \u001b[0m | \u001b[0m 8.364e-0\u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9444  \u001b[0m | \u001b[0m 0.03504 \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9442  \u001b[0m | \u001b[0m 0.04747 \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.9458  \u001b[0m | \u001b[95m 0.001066\u001b[0m |\n",
      "| \u001b[95m 19      \u001b[0m | \u001b[95m 0.9483  \u001b[0m | \u001b[95m 0.002137\u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9483  \u001b[0m | \u001b[0m 0.003116\u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9481  \u001b[0m | \u001b[0m 0.004367\u001b[0m |\n",
      "| \u001b[95m 22      \u001b[0m | \u001b[95m 0.9494  \u001b[0m | \u001b[95m 0.005708\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9494  \u001b[0m | \u001b[0m 0.007103\u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9486  \u001b[0m | \u001b[0m 0.008654\u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9472  \u001b[0m | \u001b[0m 0.01029 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.9478  \u001b[0m | \u001b[0m 0.01223 \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9475  \u001b[0m | \u001b[0m 0.01408 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.9481  \u001b[0m | \u001b[0m 0.01613 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9481  \u001b[0m | \u001b[0m 0.018   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.9478  \u001b[0m | \u001b[0m 0.02    \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9469  \u001b[0m | \u001b[0m 0.02201 \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.9458  \u001b[0m | \u001b[0m 0.02433 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.9456  \u001b[0m | \u001b[0m 0.02666 \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.9456  \u001b[0m | \u001b[0m 0.02903 \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.9456  \u001b[0m | \u001b[0m 0.03153 \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.9444  \u001b[0m | \u001b[0m 0.03842 \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9442  \u001b[0m | \u001b[0m 0.04093 \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.9442  \u001b[0m | \u001b[0m 0.04374 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9439  \u001b[0m | \u001b[0m 0.05106 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 0.05374 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.9425  \u001b[0m | \u001b[0m 0.05653 \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.9419  \u001b[0m | \u001b[0m 0.05957 \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 0.06281 \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9414  \u001b[0m | \u001b[0m 0.06624 \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.9411  \u001b[0m | \u001b[0m 0.06981 \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.07358 \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9228  \u001b[0m | \u001b[0m 0.6668  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.9214  \u001b[0m | \u001b[0m 0.8116  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.9233  \u001b[0m | \u001b[0m 0.6267  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9394  \u001b[0m | \u001b[0m 0.07872 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 0.2212  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.9392  \u001b[0m | \u001b[0m 0.08375 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9261  \u001b[0m | \u001b[0m 0.4554  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.575   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7818  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.9203  \u001b[0m | \u001b[0m 0.9622  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2545  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.4879  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.8969  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.9381  \u001b[0m | \u001b[0m 0.08731 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.9206  \u001b[0m | \u001b[0m 0.9265  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7511  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9342  \u001b[0m | \u001b[0m 0.1192  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.6934  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.9275  \u001b[0m | \u001b[0m 0.3712  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.6008  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 0.5134  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2783  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.9353  \u001b[0m | \u001b[0m 0.09978 \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.9281  \u001b[0m | \u001b[0m 0.3239  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.9211  \u001b[0m | \u001b[0m 0.8336  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.9314  \u001b[0m | \u001b[0m 0.1664  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.9397  \u001b[0m | \u001b[0m 0.07615 \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.8763  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.9231  \u001b[0m | \u001b[0m 0.6467  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.4362  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.9344  \u001b[0m | \u001b[0m 0.1071  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9197  \u001b[0m | \u001b[0m 0.9811  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.9303  \u001b[0m | \u001b[0m 0.2036  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 0.5569  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.9203  \u001b[0m | \u001b[0m 0.9443  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2377  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9258  \u001b[0m | \u001b[0m 0.4715  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.9331  \u001b[0m | \u001b[0m 0.1319  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7357  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.9392  \u001b[0m | \u001b[0m 0.08123 \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7664  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7967  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9347  \u001b[0m | \u001b[0m 0.1129  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.9444  \u001b[0m | \u001b[0m 0.04545 \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.9118  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.7068  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.3584  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.9356  \u001b[0m | \u001b[0m 0.09597 \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9272  \u001b[0m | \u001b[0m 0.384   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9222  \u001b[0m | \u001b[0m 0.6801  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.9339  \u001b[0m | \u001b[0m 0.1248  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 0.5879  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.9233  \u001b[0m | \u001b[0m 0.6136  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.925   \u001b[0m | \u001b[0m 0.5005  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 0.5261  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2902  \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2664  \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.945   \u001b[0m | \u001b[0m 0.03309 \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.9317  \u001b[0m | \u001b[0m 0.1564  \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.3347  \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.9278  \u001b[0m | \u001b[0m 0.3131  \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 0.1762  \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.8447  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.9211  \u001b[0m | \u001b[0m 0.8225  \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.9322  \u001b[0m | \u001b[0m 0.1383  \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.4071  \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.8866  \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.9306  \u001b[0m | \u001b[0m 0.1948  \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.9347  \u001b[0m | \u001b[0m 0.1034  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.9208  \u001b[0m | \u001b[0m 0.866   \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.9269  \u001b[0m | \u001b[0m 0.4266  \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.9267  \u001b[0m | \u001b[0m 0.4457  \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.9228  \u001b[0m | \u001b[0m 0.6567  \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.93    \u001b[0m | \u001b[0m 0.2122  \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.9233  \u001b[0m | \u001b[0m 0.6367  \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2461  \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.9289  \u001b[0m | \u001b[0m 0.2295  \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.9411  \u001b[0m | \u001b[0m 0.06799 \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.9244  \u001b[0m | \u001b[0m 0.5478  \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.9242  \u001b[0m | \u001b[0m 0.5659  \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\py37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.92    \u001b[0m | \u001b[0m 0.9716  \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.9194  \u001b[0m | \u001b[0m 0.9906  \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.9206  \u001b[0m | \u001b[0m 0.9354  \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.9203  \u001b[0m | \u001b[0m 0.9532  \u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.9253  \u001b[0m | \u001b[0m 0.4796  \u001b[0m |\n",
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.9261  \u001b[0m | \u001b[0m 0.4634  \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7434  \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.9317  \u001b[0m | \u001b[0m 0.1515  \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.9311  \u001b[0m | \u001b[0m 0.1614  \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.9367  \u001b[0m | \u001b[0m 0.08973 \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.9219  \u001b[0m | \u001b[0m 0.7281  \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7741  \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7587  \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.9217  \u001b[0m | \u001b[0m 0.7892  \u001b[0m |\n",
      "=====================================\n",
      "best C: 0.0057077545877518565\n"
     ]
    }
   ],
   "source": [
    "# The optimal hyperparameter C, the regularization parameter, is selected using a Bayesian optimizer\n",
    "def f_score(C):\n",
    "    lr = LogisticRegression(max_iter=200,C=C)\n",
    "    lr.fit(X_train_copy,y_train)\n",
    "    acc = accuracy_score(y_test,lr.predict(X_test_copy))\n",
    "    return acc     # The goal of adjusting parameters to maximize accuracy\n",
    "\n",
    "\n",
    "# Determine the range of parameter values\n",
    "pbounds = {'C': (0,1)}\n",
    "\n",
    "# Constructing a Bayesian Optimizer\n",
    "opt = BayesianOptimization(\n",
    "    f=f_score,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2,  # verbose = 2 prints all, verbose = 1 prints the maximum value found in the run, verbose = 0 prints nothing\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Start running\n",
    "opt.maximize(\n",
    "    init_points=10,  # Steps of random search\n",
    "    n_iter=130  # Number of iterations to perform Bayesian optimization\n",
    ")\n",
    "\n",
    "C2 = opt.max['params'][\"C\"]     # Take the best parameters\n",
    "print(\"best C:\",C2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9494444444444444\n"
     ]
    }
   ],
   "source": [
    "# Training on the training set\n",
    "lr2 = LogisticRegression(max_iter=200,C=C2)\n",
    "lr2.fit(X_train_copy,y_train)\n",
    "\n",
    "\n",
    "# Test accuracy in test set\n",
    "pre = lr2.predict(X_test_copy)\n",
    "acc = accuracy_score(pre,y_test)\n",
    "print(\"Accuracy on the test set:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the training set is expanded by flipping each image vertically, adding it to the training set, and using a Bayesian optimizer to select the best regularization parameter C for the logistic regression classifier to achieve the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16800, 784)\n",
      "(16800,)\n"
     ]
    }
   ],
   "source": [
    "# Flip all the images in the training set and expand them to the training set\n",
    "X_train_copy = X_train.tolist()\n",
    "y_train_copy = y_train.tolist()\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "for i in range(len(X_train)):\n",
    "    temp_img = []\n",
    "    img = X_train[i].reshape(28,28)\n",
    "    img_new = cv2.flip(img, 0)  # Vertical Flip\n",
    "    img_new = img_new.reshape(-1).tolist()\n",
    "    X_train_copy.append(img_new)\n",
    "    y_train_copy.append(y_train[i])\n",
    "X_train = np.array(X_train_copy)\n",
    "y_train = np.array(y_train_copy)\n",
    "print(X_train.shape)  # Print the shape of x_train\n",
    "print(y_train.shape)  # Print the shape of y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the shape of both x_train and y_train become twice the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.417   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8931  \u001b[0m | \u001b[0m 0.000114\u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.9081  \u001b[0m | \u001b[95m 0.3023  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.9083  \u001b[0m | \u001b[95m 0.1468  \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.9094  \u001b[0m | \u001b[95m 0.09234 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.1863  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3456  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.3968  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5388  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8739  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.9999  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6299  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 0.09788 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 0.09786 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.7964  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9382  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2449  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4821  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6749  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5836  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8351  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 0.1165  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.2161  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2741  \u001b[0m |\n",
      "| \u001b[95m 26      \u001b[0m | \u001b[95m 0.91    \u001b[0m | \u001b[95m 0.1091  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.7577  \u001b[0m |\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m 0.9106  \u001b[0m | \u001b[95m 0.06482 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4507  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9064  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.9702  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.9103  \u001b[0m | \u001b[0m 0.07416 \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5109  \u001b[0m |\n",
      "| \u001b[95m 34      \u001b[0m | \u001b[95m 0.9119  \u001b[0m | \u001b[95m 0.05389 \u001b[0m |\n",
      "| \u001b[95m 35      \u001b[0m | \u001b[95m 0.9131  \u001b[0m | \u001b[95m 0.04342 \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.9131  \u001b[0m | \u001b[0m 0.03813 \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 0.0406  \u001b[0m |\n",
      "| \u001b[95m 38      \u001b[0m | \u001b[95m 0.9133  \u001b[0m | \u001b[95m 0.02844 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3705  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3237  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.9083  \u001b[0m | \u001b[0m 0.1663  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6068  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6977  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6524  \u001b[0m |\n",
      "| \u001b[95m 45      \u001b[0m | \u001b[95m 0.9142  \u001b[0m | \u001b[95m 0.03235 \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5612  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.03338 \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.03287 \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8546  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8158  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.7771  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.7388  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.9089  \u001b[0m | \u001b[0m 0.1319  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.03287 \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4338  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.03186 \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2594  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.2009  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.0337  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2884  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.2308  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4664  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.9139  \u001b[0m | \u001b[0m 0.03144 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.9136  \u001b[0m | \u001b[0m 0.02422 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 0.04858 \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.9125  \u001b[0m | \u001b[0m 0.0195  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.9108  \u001b[0m | \u001b[0m 0.05899 \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.9136  \u001b[0m | \u001b[0m 0.01449 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.0111  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.9097  \u001b[0m | \u001b[0m 0.0821  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8901  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9543  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9223  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.985   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4965  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5248  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3832  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.358   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3128  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3347  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.9092  \u001b[0m | \u001b[0m 0.124   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.9083  \u001b[0m | \u001b[0m 0.1565  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.9083  \u001b[0m | \u001b[0m 0.176   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5953  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6183  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6863  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.7089  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6637  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.6411  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5724  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.9136  \u001b[0m | \u001b[0m 0.01268 \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.9136  \u001b[0m | \u001b[0m 0.00872 \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5501  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4069  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.9131  \u001b[0m | \u001b[0m 0.02626 \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.9083  \u001b[0m | \u001b[0m 0.1391  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8449  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.91    \u001b[0m | \u001b[0m 0.06944 \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8255  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8063  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.7868  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.7674  \u001b[0m |\n",
      "| \u001b[0m 103     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8642  \u001b[0m |\n",
      "| \u001b[0m 104     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.7481  \u001b[0m |\n",
      "| \u001b[0m 105     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.7296  \u001b[0m |\n",
      "| \u001b[0m 106     \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 0.04593 \u001b[0m |\n",
      "| \u001b[0m 107     \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 0.02212 \u001b[0m |\n",
      "| \u001b[0m 108     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4422  \u001b[0m |\n",
      "| \u001b[0m 109     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4254  \u001b[0m |\n",
      "| \u001b[0m 110     \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2669  \u001b[0m |\n",
      "| \u001b[0m 111     \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2522  \u001b[0m |\n",
      "| \u001b[0m 112     \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.01677 \u001b[0m |\n",
      "| \u001b[0m 113     \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.2085  \u001b[0m |\n",
      "| \u001b[0m 114     \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.1936  \u001b[0m |\n",
      "| \u001b[0m 115     \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2812  \u001b[0m |\n",
      "| \u001b[0m 116     \u001b[0m | \u001b[0m 0.91    \u001b[0m | \u001b[0m 0.1043  \u001b[0m |\n",
      "| \u001b[0m 117     \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.2234  \u001b[0m |\n",
      "| \u001b[0m 118     \u001b[0m | \u001b[0m 0.9081  \u001b[0m | \u001b[0m 0.2954  \u001b[0m |\n",
      "| \u001b[0m 119     \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.2379  \u001b[0m |\n",
      "| \u001b[0m 120     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4585  \u001b[0m |\n",
      "| \u001b[0m 121     \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.03604 \u001b[0m |\n",
      "| \u001b[0m 122     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4742  \u001b[0m |\n",
      "| \u001b[0m 123     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.882   \u001b[0m |\n",
      "| \u001b[0m 124     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.8982  \u001b[0m |\n",
      "| \u001b[0m 125     \u001b[0m | \u001b[0m 0.9094  \u001b[0m | \u001b[0m 0.08707 \u001b[0m |\n",
      "| \u001b[0m 126     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9624  \u001b[0m |\n",
      "| \u001b[0m 127     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9463  \u001b[0m |\n",
      "| \u001b[0m 128     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9303  \u001b[0m |\n",
      "| \u001b[0m 129     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9143  \u001b[0m |\n",
      "| \u001b[0m 130     \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.009911\u001b[0m |\n",
      "| \u001b[0m 131     \u001b[0m | \u001b[0m 0.9069  \u001b[0m | \u001b[0m 0.9776  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 132     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.9924  \u001b[0m |\n",
      "| \u001b[0m 133     \u001b[0m | \u001b[0m 0.9119  \u001b[0m | \u001b[0m 0.05123 \u001b[0m |\n",
      "| \u001b[0m 134     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.4893  \u001b[0m |\n",
      "| \u001b[0m 135     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5037  \u001b[0m |\n",
      "| \u001b[0m 136     \u001b[0m | \u001b[0m 0.9075  \u001b[0m | \u001b[0m 0.3897  \u001b[0m |\n",
      "| \u001b[0m 137     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5179  \u001b[0m |\n",
      "| \u001b[0m 138     \u001b[0m | \u001b[0m 0.9072  \u001b[0m | \u001b[0m 0.5319  \u001b[0m |\n",
      "| \u001b[0m 139     \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3768  \u001b[0m |\n",
      "| \u001b[0m 140     \u001b[0m | \u001b[0m 0.9078  \u001b[0m | \u001b[0m 0.3642  \u001b[0m |\n",
      "=====================================\n",
      "best C: 0.032347468638519006\n"
     ]
    }
   ],
   "source": [
    "# The optimal hyperparameter C, the regularization parameter, is selected using a Bayesian optimizer\n",
    "def f_score(C):\n",
    "    lr = LogisticRegression(max_iter=200,C=C)\n",
    "    lr.fit(X_train,y_train)\n",
    "    acc = accuracy_score(y_test,lr.predict(X_test))\n",
    "    return acc     # The goal of adjusting parameters to maximize accuracy\n",
    "\n",
    "# Determine the range of parameter values\n",
    "pbounds = {'C': (0,1)}\n",
    "\n",
    "# Constructing a Bayesian Optimizer\n",
    "opt = BayesianOptimization(\n",
    "    f=f_score, \n",
    "    pbounds=pbounds,  \n",
    "    verbose=2,  # verbose = 2 prints all, verbose = 1 prints the maximum value found in the run, verbose = 0 prints nothing\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Start running\n",
    "opt.maximize(\n",
    "    init_points=10,  # Steps of random search\n",
    "    n_iter=130  # Number of iterations to perform Bayesian optimization\n",
    ")\n",
    "\n",
    "C3 = opt.max['params'][\"C\"]     # Take the best parameters\n",
    "print(\"best C:\",C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9141666666666667\n"
     ]
    }
   ],
   "source": [
    "# Training on the training set\n",
    "lr3 = LogisticRegression(max_iter=200,C=C3)\n",
    "lr3.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# Test accuracy in test set\n",
    "pre = lr3.predict(X_test)\n",
    "acc = accuracy_score(pre,y_test)\n",
    "print(\"Accuracy on the test set:\",acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the accuracy of fitting the logistic regression classifier without any data processing is the highest, so we only save the logistic regression model without any data processing here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/logistic_regression_classifier.m']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(lr1,\"./model/logistic_regression_classifier.m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d04c09ab49aee44a5a8e7d20dbb518ff4599d0e867e8e6f2739fd09b004f17c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
